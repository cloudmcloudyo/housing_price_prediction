{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 2: Regression Challenge\n",
    "Notebook III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "#### Linear Regression Modeling\n",
    "\n",
    "\n",
    "Notebook II to IV showcase the modeling process for this project: Started from selecting most relevant features. Then a null model was established as a baseline, follwed by fitting a simple ols model. More features and engineering were added along the way as well as more complex tools such as regularization and log transformation to fine tune the model for a best result. There are 7 models included in three notebooks.\n",
    "\n",
    "\n",
    "This notebook contains the following content:\n",
    "\n",
    "- [Standardized Scaling](#Standardized-Scaling)\n",
    "- [LASSO Model](#Model-4---LASSO-Model)\n",
    "- [Ridge Model](#Model-5---Ridge-Model)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "train = pd.read_csv('../datasets/train_clean.csv')\n",
    "test = pd.read_csv('../datasets/test_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will improve my model using regularization tools. As the prep work, I will scale all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['total_sqft * overall_qual'] = train['total_sqft'] * train['overall_qual']\n",
    "test['total_sqft * overall_qual'] = test['total_sqft'] * test['overall_qual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= train.copy()\n",
    "df_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define numberical features\n",
    "num_feature = ['total_sqft',\n",
    "            'total_bath',\n",
    "            'total_bedroom',\n",
    "            'overall_qual',\n",
    "            'exter_qual',\n",
    "            'kitchen_qual',\n",
    "            'bsmt_qual',\n",
    "            'fireplace_qu',\n",
    "            'garage_finish',\n",
    "            'mas_vnr_area',\n",
    "            'garage_cars',\n",
    "            'age_sold',\n",
    "            'age_since_remod',\n",
    "            'total_sqft * overall_qual']\n",
    "\n",
    "X_num_train = df[num_feature]\n",
    "X_num_test = df_test[num_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the standardized scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# fit the train data and transform it\n",
    "Z_num_train = sc.fit_transform(X_num_train)\n",
    "\n",
    "# transform the test data so it will not influence the model\n",
    "Z_num_test = sc.transform(X_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categorical features\n",
    "cat_feature = ['neighborhood',\n",
    "              'yr_sold',\n",
    "              'ms_subclass']\n",
    "\n",
    "X_cat_train = df[cat_feature]\n",
    "X_cat_test = df_test[cat_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummify all the categorical features\n",
    "X_cat_train = pd.get_dummies(data = X_cat_train, columns = cat_feature, drop_first = True)\n",
    "X_cat_test  = pd.get_dummies(data = X_cat_test, columns = cat_feature, drop_first = True)\n",
    "\n",
    "# match testing features to training features \n",
    "X_train_only = set(X_cat_train.columns) - set(X_cat_test.columns)\n",
    "\n",
    "for missing_col in X_train_only:\n",
    "    X_cat_test[missing_col] = 0\n",
    "\n",
    "X_cat_test = X_cat_test[X_cat_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the scaled data into a dataframe \n",
    "Z_train_df = pd.DataFrame(data = Z_num_train, index = X_num_train.index, columns = num_feature)\n",
    "Z_test_df = pd.DataFrame(data = Z_num_test, index = X_num_test.index, columns = num_feature)\n",
    "\n",
    "# combine the numerical and categorical data\n",
    "X_scaled_train = Z_train_df.join(X_cat_train, on = X_cat_train.index)\n",
    "X_scaled_test = Z_test_df.join(X_cat_test, on = X_cat_test.index)\n",
    "\n",
    "# define the target variable\n",
    "y = df['saleprice']\n",
    "\n",
    "# train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_train, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train.to_csv('../assets/scaled.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - LASSO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LASSO libraries\n",
    "from sklearn.linear_model import Lasso, LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2 score is: 0.9078259117174003\n",
      "Test R2 score is: 0.9215496162363584\n",
      "RMSE is: 22270.4358639252\n"
     ]
    }
   ],
   "source": [
    "# inspired by notes from the regularization lecture\n",
    "l_alpha = np.logspace(-3, 10, 100)\n",
    "\n",
    "# find the best alpha value\n",
    "lasso_cv = LassoCV(alphas = l_alpha, cv = 5, max_iter = 50000 )\n",
    "\n",
    "# fit the lasso.cv model\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# evaluate with R2 score\n",
    "print(f'Train R2 score is: {lasso_cv.score(X_train, y_train)}')\n",
    "print(f'Test R2 score is: {lasso_cv.score(X_test, y_test)}')\n",
    "\n",
    "# evaluate with rmse\n",
    "y_hat = lasso_cv.predict(X_test)\n",
    "rmse = (metrics.mean_squared_error(y_test, y_hat)) ** 0.5\n",
    "print(f'RMSE is: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to Model 3, the LASSO model actually increased my RMSE score. The R<sup>2</sup> did not change too much. Perhaps since I do not have too many features and didn't cause too much overfitting. And thus LASSO's reducing feature effect didn't show significantly in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the actual testing data\n",
    "pred = lasso_cv.predict(X_scaled_test)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test['id']\n",
    "submission['SalePrice'] = pred\n",
    "submission.to_csv('../result/submission_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(data = lasso_cv.coef_, index = X_scaled_train.columns, columns = ['coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission has a Kaggle RMSE score of 24844.61970."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 - Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Ridge libraries\n",
    "from sklearn.linear_model import Ridge, RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2 score is: 0.9090943758307257\n",
      "Test R2 score is: 0.9215212038783754\n",
      "RMSE is: 22274.468338241983\n"
     ]
    }
   ],
   "source": [
    "# inspired by notes from the regularization lecture\n",
    "r_alphas = np.logspace(0, 5, 100)\n",
    "\n",
    "# find the best alpha value\n",
    "ridge_cv = RidgeCV(alphas = r_alphas, scoring = 'r2', cv = 5)\n",
    "\n",
    "# fit the ridge.cv model\n",
    "ridge_cv = ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# evaluate with R2 score\n",
    "print(f'Train R2 score is: {ridge_cv.score(X_train, y_train)}')\n",
    "print(f'Test R2 score is: {ridge_cv.score(X_test, y_test)}')\n",
    "\n",
    "# evaluate with rmse\n",
    "y_hat = ridge_cv.predict(X_test)\n",
    "rmse = (metrics.mean_squared_error(y_test, y_hat)) ** 0.5\n",
    "print(f'RMSE is: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ridge result didn't change much from LASSO. RMSE is almost the same and so are the R squared score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the actual test data\n",
    "pred = ridge_cv.predict(X_scaled_test)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test['id']\n",
    "submission['SalePrice'] = pred\n",
    "submission.to_csv('../result/submission_4.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission has a Kaggle RMSE score of 25077.55084, which is lower than the LASSO score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models to pickle for later stage\n",
    "\n",
    "lasso = '../assets/lasso.pkl'\n",
    "ridge = '../assets/ridge.pkl'\n",
    "\n",
    "pickle.dump(lasso_cv, open(lasso, 'wb'))\n",
    "pickle.dump(ridge_cv, open(ridge, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

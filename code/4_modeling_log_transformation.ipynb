{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 2: Regression Challenge\n",
    "Notebook IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "#### Linear Regression Modeling\n",
    "\n",
    "\n",
    "Notebook II to IV showcase the modeling process for this project: Started from selecting most relevant features. Then a null model was established as a baseline, follwed by fitting a simple ols model. More features and engineering were added along the way as well as more complex tools such as regularization and log transformation to fine tune the model for a best result. There are 7 models included in three notebooks.\n",
    "\n",
    "\n",
    "This notebook contains the following content:\n",
    "\n",
    "- [Log Transformation](#Model-6---Log-Transformation)\n",
    "- [Log Transformation Improved](#Model-7---Log-Transformation-Improved)\n",
    "- [Pickling](#Pickling)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "train = pd.read_csv('../datasets/train_clean.csv')\n",
    "test = pd.read_csv('../datasets/test_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6 - Log Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As LASSO and Ridge didn't improve my model, I'm performing log transformation on my model. Since our target variable is right skewed, the transformation will normalize it which may help our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "train['total_sqft * overall_qual'] = train['total_sqft'] * train['overall_qual']\n",
    "test['total_sqft * overall_qual'] = test['total_sqft'] * test['overall_qual']\n",
    "\n",
    "df= train.copy()\n",
    "df_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "features = ['total_sqft',\n",
    "            'total_bath',\n",
    "            'total_bedroom',\n",
    "            'neighborhood',\n",
    "            'overall_qual',\n",
    "            'exter_qual',\n",
    "            'kitchen_qual',\n",
    "            'bsmt_qual',\n",
    "            'fireplace_qu',\n",
    "            'garage_finish',\n",
    "            'fireplaces',\n",
    "            'mas_vnr_area',\n",
    "            'garage_cars',\n",
    "            'age_sold',\n",
    "            'age_since_remod',\n",
    "            'yr_sold',\n",
    "            'total_sqft * overall_qual',\n",
    "            'overall_cond',\n",
    "            'ms_subclass']\n",
    "\n",
    "X = df[features]\n",
    "X = pd.get_dummies(data = X, columns = ['neighborhood', 'yr_sold', 'ms_subclass'], drop_first = True)\n",
    "y = train['saleprice']\n",
    "features_train = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score is: 0.9089377332630848\n",
      "Test score is: 0.9332237320865686\n",
      "RMSE is: 20546.7081489154\n"
     ]
    }
   ],
   "source": [
    "# train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "# log transform the target variables\n",
    "y_train_log = y_train.map(np.log)\n",
    "y_test_log = y_test.map(np.log)\n",
    "\n",
    "# instantiate the linear regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# fit the model with logged training data\n",
    "lr.fit(X_train, y_train_log)\n",
    "\n",
    "# evaluate with R2\n",
    "print(f'Train score is: {lr.score(X_train, y_train_log)}')\n",
    "\n",
    "# exponentiate the target \n",
    "pred = lr.predict(X_test)\n",
    "pred_test = np.exp(pred)\n",
    "print(f'Test score is: {metrics.r2_score(y_test, pred_test)}')\n",
    "print(f'RMSE is: {(metrics.mean_squared_error(y_test, pred_test)) ** 0.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best model so far. I have achieved significant drop in RMSE by log transformation. Both train and test R squared scores are in the 90% category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features for actual testing data and preprocessing \n",
    "X_1 = df_test[features]\n",
    "X_1 = pd.get_dummies(data = X_1, columns = ['neighborhood', 'yr_sold', 'ms_subclass'], drop_first = True)\n",
    "features_test = X_1.columns\n",
    "\n",
    "# match testing features to training features \n",
    "\n",
    "train_only = set(features_train) - set(features_test)\n",
    "for missing_col in train_only:\n",
    "    X_1[missing_col] = 0\n",
    "X_1 = X_1[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the actual test data\n",
    "pred_log = lr.predict(X_1)\n",
    "\n",
    "# exponentiate the predicted value back to sale price\n",
    "pred_saleprice = np.exp(pred_log)\n",
    "\n",
    "# submission\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test['id']\n",
    "submission['SalePrice'] = pred_saleprice\n",
    "submission.to_csv('../result/submission_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission has a Kaggle RMSE value of 21856.70871"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7 - Log Transformation Improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is in fact just a minor upgrade from the previous model. Since log transformation has improved my model significantly, instead of using train-test-split, I can just fit the model to my entire training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and preprocessing the training data\n",
    "X = df[features]\n",
    "X = pd.get_dummies(data = X, columns = ['neighborhood', 'yr_sold', 'ms_subclass'], drop_first = True)\n",
    "y = train['saleprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score is: 0.8975296507191131\n",
      "Test Score: 0.9277140786962689\n",
      "RMSE is: 21314.328873098806\n"
     ]
    }
   ],
   "source": [
    "# instantiate the linear regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# log transformation the sale price of the entire training data\n",
    "y_log = y.map(np.log)\n",
    "\n",
    "# check the cross val score\n",
    "print(f'Cross Val Score is: {cross_val_score(lr, X, y_log).mean()}')\n",
    "\n",
    "# fit the model\n",
    "lr.fit(X, y_log)\n",
    "\n",
    "# predict the value and exponentiate\n",
    "pred = lr.predict(X)\n",
    "pred_unlog = np.exp(pred)\n",
    "\n",
    "# evaluate with R2\n",
    "print(f'Test Score: {metrics.r2_score(y, pred_unlog)}')\n",
    "\n",
    "# evaluate with RMSE\n",
    "print(f'RMSE is: {(metrics.mean_squared_error(y, pred_unlog)) ** 0.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE dropped from the previous model while test R squared score has improved. Would like to see how Kaggle score performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and preprocessing actual testing data\n",
    "X_1 = df_test[features]\n",
    "X_1 = pd.get_dummies(data = X_1, columns = ['neighborhood', 'yr_sold', 'ms_subclass'], drop_first = True)\n",
    "features_test = X_1.columns\n",
    "\n",
    "# match the features\n",
    "train_only = set(features_train) - set(features_test)\n",
    "for missing_col in train_only:\n",
    "    X_1[missing_col] = 0\n",
    "X_1 = X_1[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log = lr.predict(X_1)\n",
    "\n",
    "pred_saleprice = np.exp(pred_log)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test['id']\n",
    "submission['SalePrice'] = pred_saleprice\n",
    "submission.to_csv('../result/submission_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission has a Kaggle RMSE value of 21204.55452, which is the best Kaggle score I have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../assets/log.pkl'\n",
    "pickle.dump(lr, open(file_name, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
